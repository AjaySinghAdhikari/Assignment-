{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "5b210b2a-87a8-41ce-b8a9-2d5d7cae7ef4",
      "cell_type": "code",
      "source": "### Import Necessary Libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.linear_model import Ridge, Lasso",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "id": "ff58fb3e-aa9d-4936-bf6d-81ae2b5efff1",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a0439f93-5fb9-4e1c-88eb-2ae31526efae",
      "cell_type": "code",
      "source": "# Q1: Explain the concept of R-squared\n\"\"\"\nR-squared (R²) is a statistical measure in regression models that determines how well the independent variables explain the variability of the dependent variable.\nFormula:\n    R² = 1 - (SS_res / SS_tot)\nwhere,\n    SS_res = sum of squared residuals (actual - predicted)\n    SS_tot = total sum of squares (actual - mean(actual))\n\nValues range from 0 to 1, where 1 indicates a perfect fit.\n\"\"\"\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nR-squared (R²) is a statistical measure in regression models that determines how well the independent variables explain the variability of the dependent variable.\\nFormula:\\n    R² = 1 - (SS_res / SS_tot)\\nwhere,\\n    SS_res = sum of squared residuals (actual - predicted)\\n    SS_tot = total sum of squares (actual - mean(actual))\\n\\nValues range from 0 to 1, where 1 indicates a perfect fit.\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2
    },
    {
      "id": "e6d510b0-4664-41b7-9b2d-62c891cbb84f",
      "cell_type": "code",
      "source": "# Q2: Define adjusted R-squared and explain the difference from R-squared\n\"\"\"\nAdjusted R-squared accounts for the number of predictors in the model.\nFormula:\n    Adjusted R² = 1 - [(1 - R²) * (n - 1) / (n - p - 1)]\nwhere,\n    n = number of observations\n    p = number of predictors\nUnlike R², adjusted R² penalizes additional predictors, ensuring only useful predictors increase the score.\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nAdjusted R-squared accounts for the number of predictors in the model.\\nFormula:\\n    Adjusted R² = 1 - [(1 - R²) * (n - 1) / (n - p - 1)]\\nwhere,\\n    n = number of observations\\n    p = number of predictors\\nUnlike R², adjusted R² penalizes additional predictors, ensuring only useful predictors increase the score.\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "id": "2fdd069c-95da-4821-a7c3-51edbd07cde6",
      "cell_type": "code",
      "source": "# Q3: When to use adjusted R-squared?\n\"\"\"\nAdjusted R² is preferable when comparing models with different numbers of predictors to avoid overestimating model performance.\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nAdjusted R² is preferable when comparing models with different numbers of predictors to avoid overestimating model performance.\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "id": "a1ffcb60-825c-4e10-82b8-ef1fb1229820",
      "cell_type": "code",
      "source": "# Q4: RMSE, MSE, and MAE in regression analysis\n\"\"\"\n- Mean Squared Error (MSE) = mean((actual - predicted)^2)\n- Root Mean Squared Error (RMSE) = sqrt(MSE)\n- Mean Absolute Error (MAE) = mean(|actual - predicted|)\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n- Mean Squared Error (MSE) = mean((actual - predicted)^2)\\n- Root Mean Squared Error (RMSE) = sqrt(MSE)\\n- Mean Absolute Error (MAE) = mean(|actual - predicted|)\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5
    },
    {
      "id": "2102756d-b68a-4aa0-89ef-824eba8ab501",
      "cell_type": "code",
      "source": "def calculate_metrics(y_true, y_pred):\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    mae = mean_absolute_error(y_true, y_pred)\n    return mse, rmse, mae\n\n# Example\nactual = np.array([3, -0.5, 2, 7])\npredicted = np.array([2.5, 0.0, 2, 8])\n\nmse, rmse, mae = calculate_metrics(actual, predicted)\nprint(f\"MSE: {mse}, RMSE: {rmse}, MAE: {mae}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "MSE: 0.375, RMSE: 0.6123724356957945, MAE: 0.5\n"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "3d061075-ad5c-4fb4-8057-caa5a5c0aadc",
      "cell_type": "code",
      "source": "# Q5: Advantages and disadvantages of RMSE, MSE, and MAE\n\"\"\"\n- MSE penalizes large errors more but is not interpretable due to squared units.\n- RMSE is in the same unit as the target variable and penalizes large errors.\n- MAE is more interpretable but treats all errors equally, making it less sensitive to large errors.\n\"\"\"\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n- MSE penalizes large errors more but is not interpretable due to squared units.\\n- RMSE is in the same unit as the target variable and penalizes large errors.\\n- MAE is more interpretable but treats all errors equally, making it less sensitive to large errors.\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7
    },
    {
      "id": "30a62970-c3d8-44e6-a3a1-06600b1f15af",
      "cell_type": "code",
      "source": "# Q6: Lasso vs. Ridge Regularization\n\"\"\"\n- Lasso (L1 regularization) can shrink some coefficients to zero, performing feature selection.\n- Ridge (L2 regularization) reduces coefficients but does not eliminate them.\n- Lasso is preferred when sparsity is desired, whereas Ridge is useful when all predictors contribute.\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n- Lasso (L1 regularization) can shrink some coefficients to zero, performing feature selection.\\n- Ridge (L2 regularization) reduces coefficients but does not eliminate them.\\n- Lasso is preferred when sparsity is desired, whereas Ridge is useful when all predictors contribute.\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "id": "253eceab-4ef8-41be-9a42-6550b65f5c22",
      "cell_type": "code",
      "source": "# Q7: Preventing Overfitting with Regularization\n\"\"\"\nRegularized models prevent overfitting by constraining coefficient values, reducing variance while maintaining predictive performance.\nExample:\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\nRegularized models prevent overfitting by constraining coefficient values, reducing variance while maintaining predictive performance.\\nExample:\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "id": "b6aac6ca-894e-4eb6-8413-f4647aa12a2b",
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Simulated Data\nX = np.random.rand(100, 5)\ny = 3 * X[:, 0] + 2 * X[:, 1] + np.random.randn(100)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nridge = Ridge(alpha=1.0)\nridge.fit(X_train, y_train)\nprint(\"Ridge Coefficients:\", ridge.coef_)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Ridge Coefficients: [ 2.32879066  1.92082889  0.18205001 -0.54022808 -0.28211601]\n"
        }
      ],
      "execution_count": 10
    },
    {
      "id": "7b7c6633-6481-420b-b704-65cc2408e96e",
      "cell_type": "code",
      "source": "# Q8: Limitations of Regularized Models\n\"\"\"\n- They may not work well with non-linear relationships.\n- Choosing the right regularization parameter is crucial.\n- Lasso might drop important variables if lambda is too high.\n\"\"\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'\\n- They may not work well with non-linear relationships.\\n- Choosing the right regularization parameter is crucial.\\n- Lasso might drop important variables if lambda is too high.\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11
    },
    {
      "id": "1830049e-9285-4521-ad59-c6839ae2721c",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}